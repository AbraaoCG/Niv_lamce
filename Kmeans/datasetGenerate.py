# -*- coding: utf-8 -*-
"""Kmeans_Teste+Erros.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ATLkMQgZHCB9-CwewQJORBUsa02VxzX_

# Importação e análise inicial dos dados
"""

# libraries
from sklearn import cluster
import numpy as np

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()


data = sns.load_dataset("iris")

# Definir porcentagem de dados utilizado para teste, número de grupos e legenda correta de agrupamento, caso exista ( para cálculo de erro no final.)
PorcentTeste = 10
numGrupos = 3

# Nome do 'y' para agrupamento.
legenda_agrupamento = 'species'
# Definir Características utilizadas na classificação
selected_var = ['sepal_width', 'petal_length', 'petal_width']

# Defino tamanho do teste
tamData = len(data)
numLinTeste = int(tamData * (PorcentTeste / 100))
print(" Número de objetos de treino: ", (tamData - numLinTeste))
print(" Número de objetos de teste: ", numLinTeste)
print("Número de variáveis / características:  ", len(selected_var))
# Crio função para obter lista de indexes pseudo-aleatórios para serem usados em teste, garantindo não repetição.


def getRandomIndexes(all_index, numLinTeste):
    random_Test_indexes = []
    for x in range(numLinTeste):
        tmp_int = np.random.choice(all_index, size=1)
        all_index.remove(tmp_int[0])
        random_Test_indexes.append(tmp_int[0])
    return random_Test_indexes


# Separo variáveis utilizadas para classificação, exceto 'species'
data = data[selected_var + [legenda_agrupamento]]
# Obtenho Linha de indexes randômicos.
all_index = data.index.values.tolist()
random_Test_indexes = getRandomIndexes(all_index, numLinTeste)
# Separo DataFrames de Teste e Treino, além de armazenar agrupamento original do segmento de teste.
data_Teste = data.iloc[random_Test_indexes]
data_Treino = data.drop(random_Test_indexes, axis=0)
Agrupamento_original_treino = data_Treino[legenda_agrupamento]
data_Treino.drop([legenda_agrupamento], axis=1, inplace=True)
Agrupamento_original_teste = data_Teste[legenda_agrupamento]
data_Teste.drop([legenda_agrupamento], axis=1, inplace=True)

""" Print de indexes de treino e teste

# Print indexes de Treino
print(" Indexes de Treino: ")
print(data_Treino.index.values)
# Print indexes de Teste
print(" Indexes de Teste: ")
print(data_Treino.index.values)

"""

num_grupos_dataset = numGrupos
# Obtenho lista com nomes de cada tipo de objeto / label.
group_labels = data[legenda_agrupamento].unique()

# Crio dataset para centroide original
Centroide_original = pd.DataFrame(
    columns=data_Teste.columns, index=group_labels)
Centroide_original.fillna(0.0, inplace=True)

# Calculando centroides do dataset original com classificação original (de especialista) ( Faz-se aqui apenas a soma dos valores encontrados, posteriormente a média)
for item in data.index.values:  # Percorre index de todos os objetos.
    for group in group_labels:       # percorre nome dos grupos
        if (data[legenda_agrupamento][item] == group):
            # percorre nome das variáveis que dão dimensão à classificação.
            for dimension in data_Teste:
                Centroide_original[dimension][group] += data[dimension][item]

# determinar número de objetos em cada grupo no Dataset Original.
agrup_original = data[legenda_agrupamento].to_numpy()
num_objetos_original = pd.value_counts(agrup_original)
Centroide_original = pd.concat([Centroide_original, pd.DataFrame(
    {'numObjetos': num_objetos_original})], axis=1)

# Cálculo da média de cada variável, divindo pelo número de objetos classificados em cada grupo.
for group in group_labels:
    for dimension in data_Teste:
        Centroide_original[dimension][group] = Centroide_original[dimension][group] / \
            Centroide_original['numObjetos'][group]


# Adicionar nome à coluna de indexes:
data_Treino.index.names = ['index']
data_Teste.index.names = ['index']
Centroide_original.index.names = ['index']

# Substituir nomes de grupos por numeração do centroide original ( preparação para usar esses dados de agrupamento original no código de fortran).
print(Centroide_original.index.values[0])

for numeracao in range(len(Centroide_original.index.values)):
    for nameGroup in Agrupamento_original_treino:
        Agrupamento_original_treino.replace(
            Centroide_original.index.values[numeracao], numeracao, inplace=True)
    for nameGroup in Agrupamento_original_teste:
        Agrupamento_original_teste.replace(
            Centroide_original.index.values[numeracao], numeracao, inplace=True)

# Objetivo : gerar: datasets completo; dataset treino; agrupamento original treino; dataset teste; agrupamento original este; Centroide treino dataset original.
data.to_csv(
    'Datasets/dataset_completo.txt', sep='\t', index=False)

data_Treino.to_csv('Datasets/dataset_treino.txt', sep='\t',
                   index=True, header=True)

Agrupamento_original_treino.to_csv(
    'agrupamentoOriginal/agrup_original_treino.txt', sep='\t', index=False, header=True)

data_Teste.to_csv('Datasets/dataset_teste.txt',
                  sep='\t', index=True, header=True)

Agrupamento_original_teste.to_csv(
    'agrupamentoOriginal/agrup_original_teste.txt', sep='\t', index=False, header=True)

Centroide_original.drop(['numObjetos'], axis=1).to_csv(
    'Resultado_Plot/Centroide_Original.txt', sep='\t', index=True, header=False)
