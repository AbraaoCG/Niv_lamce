# -*- coding: utf-8 -*-
"""Kmeans_Teste+Erros.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ATLkMQgZHCB9-CwewQJORBUsa02VxzX_

# Importação e análise inicial dos dados
"""

# libraries
from sklearn import cluster
import numpy as np

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()

data = sns.load_dataset("iris")

iris = data

iris.info()

iris.describe().T

sns.pairplot(iris, hue="species")

# Plot da classificação Original com todos os pontos.

#fig, (axe1) = plt.subplots(1 ,figsize=(10,10))

#sns.scatterplot(data=iris, x='sepal_length', y='sepal_width', hue='species', ax=axe1).set

"""# Classificação com Teste e Erros"""

# Definir porcentagem de dados utilizado para teste, número de grupos e legenda correta de agrupamento, caso exista ( para cálculo de erro no final.)
PorcentTeste = 10
numGrupos = 3
legenda_agrupamento = 'species'

# Definir Características utilizadas na classificação
selected_var = ['sepal_width', 'petal_length', 'petal_width']

# Defino tamanho do teste
tamData = len(data)
numLinTeste = int(tamData * (PorcentTeste / 100))
print(" Número de objetos de teste: ", numLinTeste)

# Crio função para obter lista de indexes pseudo-aleatórios para serem usados em teste, garantindo não repetição.


def getRandomIndexes(all_index, numLinTeste):
    random_Test_indexes = []
    for x in range(numLinTeste):
        tmp_int = np.random.choice(all_index, size=1)
        all_index.remove(tmp_int[0])
        random_Test_indexes.append(tmp_int[0])
    return random_Test_indexes


# Separo variáveis utilizadas para classificação, exceto 'species'
iris_data = data[selected_var + ['species']]
# Obtenho Linha de indexes randômicos.
all_index = iris_data.index.values.tolist()
random_Test_indexes = getRandomIndexes(all_index, numLinTeste)
# Separo DataFrames de Teste e Treino, além de armazenar agrupamento original do segmento de teste.
iris_data_Teste = iris_data.iloc[random_Test_indexes]
iris_data_Treino = iris_data.drop(random_Test_indexes, axis=0)
Agrupamento_original_treino = iris_data_Treino['species']
iris_data_Treino.drop(['species'], axis=1, inplace=True)
Agrupamento_original_teste = iris_data_Teste['species']
iris_data_Teste.drop(['species'], axis=1, inplace=True)

print(" Indexes de Teste: ")
print(random_Test_indexes)

iris_data.drop('species', axis=1).to_csv(
    'dataset_treino.txt', sep='\t', index=False)

kmeans = cluster.KMeans(numGrupos)
clusters = kmeans.fit_predict(iris_data_Treino)
clusters_DF = pd.DataFrame({'Agrupamento': clusters},
                           index=iris_data_Treino.index)

#clusters_DF.to_csv('agrupamento_iris_Sklearn.txt', sep = '\t' )

headers_df = iris_data_Treino.columns
centroides_Treino = pd.DataFrame(kmeans.cluster_centers_, columns=headers_df)
x_center, y_center = kmeans.cluster_centers_[
    :, 0], kmeans.cluster_centers_[:, 1]


iris_data_Treino_avalia = pd.concat(
    [iris_data_Treino, clusters_DF, Agrupamento_original_treino], axis=1)
iris_data_Treino_avalia

pd.value_counts(clusters_DF['Agrupamento'])

# Crio uma tabela para armazenar agrupamento gerado pelo treino e o agrupamento original do segmento de teste.
iris_data_Teste_agrupado = pd.concat(
    [iris_data_Teste, Agrupamento_original_teste], axis=1)

# Agrupamento dos pontos de teste em função de suas distâncias aos centroides gerados pelo treinamento.
agrup = np.ndarray(len(iris_data_Teste))
cont = 0
for point in random_Test_indexes:
    sumsquare = 0
    distMin = np.Inf
    for group in range(len(centroides_Treino)):
        sumquadrados = 0
        for dimension in iris_data_Teste:
            sumquadrados += (iris_data_Teste[dimension][point] -
                             centroides_Treino[dimension][group]) ** 2
        distancia_PC = np.sqrt(sumquadrados)
        if (distancia_PC < distMin):
            distMin = distancia_PC
            agrup[cont] = int(group)
    cont += 1
agrup_df = pd.DataFrame({'Agrupamento': agrup}, index=random_Test_indexes)
iris_data_Teste_agrupado = pd.concat(
    [iris_data_Teste_agrupado, agrup_df], axis=1)
# iris_data_Teste_agrupado

iris_data_Teste_agrupado

agrup_original = iris_data['species'].to_numpy()
num_objetos_original = pd.value_counts(agrup_original)
type(num_objetos_original)

# Para calcular o Erro, posso calcular centroides da classificação original e, assim, realizar uma tentativa de igualar grupos formados com grupos reais.
# Exmp do dataset Iris --> Grupo 0 : 'virgínica' ; Grupo1 : 'Setosa' ; Grupo 2 :  'versicolor'

num_grupos_dataset = numGrupos
# Obtenho lista com nomes de cada tipo de objeto / label.
group_labels = iris_data[legenda_agrupamento].unique()

# Crio dataset para centroide original
Centroide_original = pd.DataFrame(
    columns=iris_data_Teste.columns, index=group_labels)
Centroide_original.fillna(0.0, inplace=True)

for item in iris_data.index.values:  # index do objeto de Teste
    for group in group_labels:  # legenda dos grupos
        if (iris_data[legenda_agrupamento][item] == group):
            for dimension in iris_data_Teste:  # legenda das dimensões
                Centroide_original[dimension][group] += iris_data[dimension][item]

Centroide_original = pd.concat([Centroide_original, pd.DataFrame(
    {'numObjetos': num_objetos_original})], axis=1)

for group in group_labels:
    for dimension in iris_data_Teste:
        Centroide_original[dimension][group] = Centroide_original[dimension][group] / \
            Centroide_original['numObjetos'][group]


# Equivalencia de Grupo classificado e classificação real.
Centroide_original['Agrupam_correspondencia'] = -1
tmp1 = Centroide_original.drop(
    columns=['numObjetos', 'Agrupam_correspondencia'])

for orig_centr in Centroide_original.index.values:
    min_dist = np.Inf
    for classif_centr in centroides_Treino.index.values:
        a = tmp1.loc[[orig_centr]].to_numpy()
        b = centroides_Treino.iloc[[classif_centr]].to_numpy()
        dist_atual = np.linalg.norm(a - b)
        if (dist_atual < min_dist):
            min_dist = dist_atual
            minDist_label = classif_centr
    Centroide_original['Agrupam_correspondencia'][orig_centr] = minDist_label

print(" Equivalenência estimada entre agrupamento K Means e nome do grupo: ")
Centroide_original['Agrupam_correspondencia']

# iris_data_Treino_avalia

# Cálculo de erro do Treino, caso seja conhecido o número de grupos original

erros_Treino = []
numErros_Treino = 0
for item in iris_data_Treino_avalia.index.values:
    grupo_item = iris_data_Treino_avalia['species'][item]
    correspondencia_classif = Centroide_original['Agrupam_correspondencia'][grupo_item]
    if (iris_data_Treino_avalia['Agrupamento'][item] != correspondencia_classif):
        #print(iris_data_Treino_avalia['Agrupamento'][item] , "      " , correspondencia_classif)
        erros_Treino.append(item)
        numErros_Treino += 1
print("Lista de Erros de Treino:", erros_Treino)
print("Números de Erros de Treino: ", numErros_Treino)
print("% de Erros : ", (numErros_Treino / (tamData - numLinTeste)) * 100, "%")

# Cálculo de erro do Teste, caso seja conhecido o número de grupos original

erros_Teste = []
numErros_Teste = 0
for item in iris_data_Teste_agrupado.index.values:
    grupo_item = iris_data_Teste_agrupado['species'][item]
    correspondencia_classif = Centroide_original['Agrupam_correspondencia'][grupo_item]
    if (iris_data_Teste_agrupado['Agrupamento'][item] != correspondencia_classif):
        erros_Teste.append(item)
        numErros_Teste += 1
print("Lista de Erros de Teste :", erros_Teste)
print("Números de Erros de Teste: ", numErros_Teste)
print("Números de Testes : ", numLinTeste)
if (numLinTeste != 0):
    print("% de Erros na testagem : ", (numErros_Teste / numLinTeste) * 100, "%")


"""# Plots da Seção anterior"""

# Colocar dimensao de 2 variaveis


x_center_orig = Centroide_original[selected_var[0]]
y_center_orig = Centroide_original[selected_var[1]]


# Plot dos dados de treino sem classificação
#fig, (axe1) = plt.subplots(figsize=(20,10))
#axe1 = sns.scatterplot(data=iris_data_Treino, x='sepal_length', y='sepal_width', ax = axe1).set(title='Dados de Treino sem classificação' )

# plt.show()

# Plot da classificação do K Means com o segmento de Treino e Plot do dataset original com centroides criados a partir deste.
fig, (axe1, axe2) = plt.subplots(1, 2, figsize=(28, 10))

sns.scatterplot(data=iris_data_Treino_avalia, x=selected_var[0], y=selected_var[1],
                hue='Agrupamento', ax=axe1).set(title='Classificaçao de Treino')
axe1.scatter(x=x_center, y=y_center, s=300, color='red')
sns.scatterplot(data=iris_data_Treino_avalia, x=selected_var[0], y=selected_var[1],
                hue="species", ax=axe2).set(title='Classificaçao Especialista ')

# axe2.scatter(x=x_center_orig, y=y_center_orig, s = 300, color='green') ----> Centroides dataset Original.
# plt.show()
plt.savefig('Sns_plots/Class_KMeans_Treino+Especialista.png')


red_pallete_list = []
for agrup in iris_data_Treino_avalia.loc[erros_Treino]['Agrupamento'].unique():
    red_pallete_list.append('red')

fig, (axe1) = plt.subplots(1, figsize=(28, 10))
sns.scatterplot(data=iris_data_Treino_avalia, x=selected_var[0], y=selected_var[1],
                hue='Agrupamento', ax=axe1).set(title='Classificaçao de Treino')
axe1.scatter(x=x_center_orig, y=y_center_orig, s=300, color='green')
sns.scatterplot(data=iris_data_Treino_avalia.loc[erros_Treino], x=selected_var[0], y=selected_var[1],
                ax=axe1, hue='Agrupamento', palette=red_pallete_list).set(title='Exibicao de erros em vermelho')

# plt.show()
plt.savefig('Sns_plots/Class_KMeans_Treino_Erros.png')


# iris_data_Teste_agrupado

# Plot da classificação do K Means com o segmento de Teste e Plot do dataset original com centroides criados a partir deste.
fig, (axe1, axe2) = plt.subplots(1, 2, figsize=(28, 10))

sns.scatterplot(data=iris_data_Teste_agrupado, x=selected_var[0], y=selected_var[1],
                hue='Agrupamento', ax=axe1).set(title='Classificaçao de Teste')
axe1.scatter(x=x_center, y=y_center, s=300, color='red')
sns.scatterplot(data=iris_data_Teste_agrupado, x=selected_var[0], y=selected_var[1],
                hue="species", ax=axe2).set(title='Classificaçao Especialista ')

# axe2.scatter(x=x_center_orig, y=y_center_orig, s = 300, color='green') ----> Centroides dataset Original.
# plt.show()
plt.savefig('Sns_plots/Class_KMeans_Teste+Especialista.png')

red_pallete_list = []
for agrup in iris_data_Teste_agrupado.loc[erros_Teste]['Agrupamento'].unique():
    red_pallete_list.append('red')

fig, (axe1) = plt.subplots(1, figsize=(28, 10))
sns.scatterplot(data=iris_data_Teste_agrupado, x=selected_var[0], y=selected_var[1],
                hue='Agrupamento', ax=axe1).set(title='Classificaçao de Teste')
axe1.scatter(x=x_center_orig, y=y_center_orig, s=300, color='green')
sns.scatterplot(data=iris_data_Teste_agrupado.loc[erros_Teste], x=selected_var[0], y=selected_var[1],
                ax=axe1, hue='Agrupamento', palette=red_pallete_list).set(title='Exibicao de erros em vermelho')


# plt.show()
plt.savefig('Sns_plots/Class_KMeans_Teste_Erros.png')


Centroide_original['Agrupam_correspondencia'].to_csv(
    'Sns_plots/Agrup_Correespondencia.txt', sep='\t')

iris_data_Treino.to_csv('dataset_treino.txt', sep='\t', index=False)
iris_data_Teste.to_csv('dataset_teste.txt', sep='\t', index=False)
Centroide_original.drop(['numObjetos', 'Agrupam_correspondencia'], axis=1).to_csv(
    'Centroide_Original.txt', sep='\t', index=False, header=False)
