# -*- coding: utf-8 -*-
"""Kmeans_Teste+Erros.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ATLkMQgZHCB9-CwewQJORBUsa02VxzX_

# Importação e análise inicial dos dados
"""

# libraries
from sklearn import cluster
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os as os

# -------------------------------------------------------------------------------------------

# Em ordem, Definir:
# Porcentagem de dados utilizado para teste.
# Número de grupos.
# Legenda correta de agrupamento, caso exista (para cálculo de erro no final).
# Características utilizadas na classificação.
# Se os dados devem ser lidos ou importados do Seaborn
# Se os dados já estão agrupados ou não ( se não, não há como calcular erro)
# Nome do arquivo de entrada.

PorcentTeste = 10
numVizinhos_porcent = 5  # Número de vizinhos em % do dataSet

legenda_agrupamento = 'Heart Disease'  # 'species'
selected_var = ['Max HR', 'Age', 'Chest pain type', 'Cholesterol',
                'ST depression', 'Slope of ST']  # ['sepal_width', 'petal_length', 'petal_width']

#selected_var = ['BP', 'Cholesterol', 'Max HR', 'ST depression', 'Slope of ST']
#selected_var = ['Cholesterol']
dataRead = True

fileName = 'dataSets/Heart_Disease_Prediction.txt'
# -------------------------------------------------------------------------------------------

# Leitura de dados
sns.set()
if (dataRead == False):
    data = sns.load_dataset("iris")
else:
    separator = ','
    data = pd.read_csv(fileName, sep=separator)

# Leitura do número de

numVizinhos = len(data) * (numVizinhos_porcent / 100)
print ( "Número de vizinhos que serão considerados pelo algorítimo = " , numVizinhos)


# Possibilidade de printar correlação
plotCorrelation = False
if (plotCorrelation):
    sns.pairplot(data, hue=legenda_agrupamento)
    plt.savefig('dataSets/Tabela_Correlação.png')

# Defino tamanho do teste
tamData = len(data)
numLinTeste = int(tamData * (PorcentTeste / 100))
print(" Número de objetos de treino: ", (tamData - numLinTeste))
print(" Número de objetos de teste: ", numLinTeste)
print("Número de variáveis / características:  ", len(selected_var))
# Crio função para obter lista de indexes pseudo-aleatórios para serem usados em teste, garantindo não repetição.


def getRandomIndexes(all_index, numLinTeste):
    random_Test_indexes = []
    for x in range(numLinTeste):
        tmp_int = np.random.choice(all_index, size=1)
        all_index.remove(tmp_int[0])
        random_Test_indexes.append(tmp_int[0])
    return random_Test_indexes


data = data[selected_var + [legenda_agrupamento]]


# # Tratar nome de colunas ( retirando espaços )
columns_old = data.columns
columns_new = []
for column in columns_old:
    columns_new.append(column.replace(' ', '_'))
    if (column == legenda_agrupamento):
        legenda_agrupamento = column.replace(' ', '_')
data.columns = columns_new

# Obtenho Linha de indexes randômicos.
all_index = data.index.values.tolist()
random_Test_indexes = getRandomIndexes(all_index, numLinTeste)
# Separo DataFrames de Teste e Treino, além de armazenar agrupamento original do segmento de teste.
data_Teste = data.iloc[random_Test_indexes]
data_Treino = data.drop(random_Test_indexes, axis=0)

# Separo agrupamento original, se existente

Agrupamento_original_treino = data_Treino[legenda_agrupamento]
Agrupamento_original_teste = data_Teste[legenda_agrupamento]
data_Treino.drop([legenda_agrupamento], axis=1, inplace=True)
data_Teste.drop([legenda_agrupamento], axis=1, inplace=True)

""" Print de indexes de treino e teste

# Print indexes de Treino
print(" Indexes de Treino: ")
print(data_Treino.index.values)
# Print indexes de Teste
print(" Indexes de Teste: ")
print(data_Treino.index.values)

"""

Agrupamento_original_treino.to_csv(
    'agrupamentoOriginal/agrup_original_treino.txt', sep='\t', index=False, header=True)

Agrupamento_original_teste.to_csv(
    'agrupamentoOriginal/agrup_original_teste.txt', sep='\t', index=False, header=True)

# Adicionar nome à coluna de indexes:
data_Treino.index.names = ['index']
data_Teste.index.names = ['index']

# Gerar tabela com argumentos
args = [len(selected_var), (tamData - numLinTeste), numVizinhos]

args = pd.DataFrame({'argumentosKMeans': args}, index=[
                    'numVar', 'numLinhasTreino', 'numVizinhos'])

# Objetivo : gerar: arquivo com argumentos K Means; datasets completo; dataset treino; agrupamento original treino; dataset teste.

args.to_csv(
    'argsKnn.txt', sep='\t', index=True, header=False)

data.to_csv(
    'dataSets/dataset_completoKnn.txt', sep='\t', index=False)

data_Treino.to_csv('dataSets/dataset_treinoKnn.txt', sep='\t',
                   index=True, header=True)


data_Teste.to_csv('dataSets/dataset_testeKnn.txt',
                  sep='\t', index=True, header=True)

# Deleçao de arquivos de agrupamento anteriores.


if (os.path.exists('Resultado_PlotKnn/grupo1.txt')):
	os.remove('Resultado_PlotKnn/grupo1.txt')
if (os.path.exists('Resultado_PlotKnn/grupo2.txt')):
	os.remove('Resultado_PlotKnn/grupo2.txt')
if (os.path.exists('Resultado_PlotKnn/grupo3.txt')):
	os.remove('Resultado_PlotKnn/grupo3.txt')
if (os.path.exists('Resultado_PlotKnn/grupo4.txt')):
	os.remove('Resultado_PlotKnn/grupo4.txt')
if (os.path.exists('Resultado_PlotKnn/grupo5.txt')):
	os.remove('Resultado_PlotKnn/grupo5.txt')
